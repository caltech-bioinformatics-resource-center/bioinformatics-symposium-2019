# Tips for software installation

# Cheatsheet: commands for kallisto and BUStools

### kallisto index
Prior to running kallisto, it is necessary to build a kallisto index using the transcriptome of the species being analyzed. The index is like a lookup table that let's kallisto very quickly map which reads belong to which transcript. This index needs to be built only once for each species to be analyzed, given a k-mer size (kallisto default is 31, the maximum size). For example, if building the index for the mouse transcriptome downloaded from Ensembl, the folowing command would be used. 
```
kallisto index -i mouse.idx Mus_musculus.GRCm38.cdna.all.fa 
```
Building the index usually takes 15-20 min on most desktop computers. A few commonly used indices are available for download at https://github.com/pachterlab/kallisto-transcriptome-indices/releases

Example output seen when building the index:
```
[build] loading fasta file Mus_musculus.GRCm38.cdna.all.fa
[build] k-mer length: 31
[build] warning: clipped off poly-A tail (longer than 10)
        from 600 target sequences
[build] warning: replaced 3 non-ACGUT characters in the input sequence
        with pseudorandom nucleotides
[build] counting k-mers ... done.
[build] building target de Bruijn graph ...  done 
[build] creating equivalence classes ...  done
[build] target de Bruijn graph has 711215 contigs and contains 98989067 k-mers 
```

**Warning:** A very common mistake is to give the sample fastq files when building the index, which are usually several GB large (teh transcriptome is usually ~100MB large). This results in kallisto running for a long time until you get a memory error. Always make sure you're giving kallisto the transcriptome and not your sample files when building the index.

### running kallisto bus
It is possible to run kallisto on multiple samples with paired end reads on multiple files at once - you just need to feed the samples paired end reads in order. For example, if you had 4 mouse samples to run from a 10x v2 experiment:
```
!kallisto bus -i mouse.idx  -o bus_output -x 10xv2 -t 2 \
./path/to/fastqs/sample1_read1.fastq.gz ./path/to/fastqs/sample1_read2.fastq.gz \
./path/to/fastqs/sample2_read1.fastq.gz ./path/to/fastqs/sample2_read2.fastq.gz \
./path/to/fastqs/sample3_read1.fastq.gz ./path/to/fastqs/sample3_read2.fastq.gz \
./path/to/fastqs/sample4_read1.fastq.gz ./path/to/fastqs/sample4_read2.fastq.gz \
```

Example output from running `kallisto bus`:
```
[index] k-mer length: 31
[index] number of targets: 115,270
[index] number of k-mers: 98,989,067
[index] number of equivalence classes: 419,171
[quant] will process sample 1: ./neuron_1k_v2_fastqs/neuron_1k_v2_S1_L001_R1_001.fastq.gz
                               ./neuron_1k_v2_fastqs/neuron_1k_v2_S1_L001_R2_001.fastq.gz
[quant] will process sample 2: ./neuron_1k_v2_fastqs/neuron_1k_v2_S1_L002_R1_001.fastq.gz
                               ./neuron_1k_v2_fastqs/neuron_1k_v2_S1_L002_R2_001.fastq.gz
[quant] finding pseudoalignments for the reads ... done
[quant] processed 104,846,299 reads, 73,297,108 reads pseudoaligned
```

A quick sanity check to catch errors is the number of reads aligned: typically this is about 70% of the reads processed or higher.


### BUStools sort and text

To use BUStools make sure that it is installed on your machine or that you can call the executable file from the terminal. Binaries are currently available for linux and mac at https://github.com/BUStools/bustools/releases. If you prefer to compile from source (harder), see https://github.com/BUStools/bustools for installation instructions.

The ```output.bus``` is a binary file. To work with it, we first convert it to a `.txt` file. To produce the text file we first sort the ```output.bus``` file and save that sorted file as ```output.sorted.txt``` and then we convert the sorted file to a `.txt` file. We can sort and convert it to `.txt` with the `bustools sort` and `bustools text` commands, shown below as an example. 

```
bustools sort -o ./bus_output/output.sorted.bus ./bus_output/output.bus
```

```
bustools text -o ./bus_output/output.sorted.txt ./bus_output/output.sorted.bus
```

## Understanding the kallisto output


### The matrix.ec file
The `matrix.ec` is generated by kallisto and connects the equivalence class ids to sets of transcripts. The format looks like
```
0    0
1    1
2    2
3    3
4    4
...

884398    26558,53383,53384,69915,69931,85319,109252,125730
884399    7750,35941,114698,119265
884400    9585,70083,92571,138545,138546
884401    90512,90513,134202,159456
```
### The `transcripts.txt` file

The transcript id correspond to the line number in the output file `transcripts.txt`. It is just a list of transcript names, like this:
```
ENSMUST00000177564.1
ENSMUST00000196221.1
ENSMUST00000179664.1
ENSMUST00000178862.1
ENSMUST00000178537.1
ENSMUST00000179520.1
...
```

### The `.bus` file format

The `output.bus` file is in binary, but after sorting and converting it to `.txt` it will look like the table below.
The first column correspond to the cellular barcode, e.g. `AAAAAATTATACATTG` in this excerpt from a 10x v2 run.
The second column is the UMI, which is 10bp for 10v2 here, e.g. `GTTGTAAGCA`
The third column is the equivalence class id that this reads belongs to. You use the matrix.ec file discussed above to map it to a set of transcripts.
The fourth column is a "multiplicity" column: how many times an identical read was seen (same cell barcode, same UMI, sam equivalence class)
Optionally there can be a fifth column for flags that is not currently used.
```
AAAAAAAAAAAAAAAA        AAAAAAAAAA      182423  1
AAAAAAAAAAAAAAAA        AAAAAAAAAA      289633  1
AAAAAAAAAAAAAAAA        AAAAAAAAAA      312535  2
AAAAAAAAAAAAAAAA        AAAAAAAAAA      313280  2
AAAAAAAAAAAAAAAA        AAAAAAAAAA      358999  1
AAAAAAAAAAAAAAAA        AAAAAAAAAA      1267062 1
AAAAAAACAAAAAAAA        AAAAAAAAAA      1258518 1
AAAAAAATCTAACAAT        AGAAGCGTTC      791583  1
AAAAAAGTTAAACTAT        GTTGTAAGCA      306697  1
AAAAAATTATACATTG        GTGCTCTAGC      138858  1
AAAAACATTTCTTTTC        TCTTTGTTTT      330396  1
AAAAACTATAGTATAA        GTTTGAAATT      116900  1
AAAAAGACAGATGTAT        CACTGTTTCA      98768   1
AAAAAGCAAAGCTAGT        TCTCACATGG      310512  1
AAAAAGGATTATGAAG        AAATTGGACC      458321  1
```

## Handy one liner to generate transcript to gene file
The transcript to gene file (`t2g.txt in the example below) is needed to map the transcript list on the bus file back to genes. Below is an example of using a one liner to generate this file starting from a mouse transcriptome, `Mus_musculus.GRCm38.cdna.all.fa `.
```
cat ./Mus_musculus.GRCm38.cdna.all.fa | awk '{if($1~/>/)print $1"\t"$4"\t"$7}' > t2g.txt; sed -i 's/>//g' t2g.txt; sed -i 's/gene://g' t2g.txt; sed -i 's/gene_symbol://g' t2g.txt
```

# Walkthrough: How to download sequencing data from the SRA 

In this example we will look at some bulk RNA-seq samples from the 2018 article [Sirt1 protects from K-Ras-driven lung carcinogenesis](https://doi.org/10.15252/embr.201643879). Let's try to download the reads for sample `GSM3168965` from RNA-Seq experiment `GSE115179`. 
The GEO ("Gene Expression Omnibus") page for this experiment is  https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE115179

Notice that there is no download option for the raw data anywhere - only for summaries of the data. The [GEO help page](https://www.ncbi.nlm.nih.gov/geo/info/download.html) simply says:
_All the data in GEO can be downloaded in a variety of formats using a variety of mechanisms._

In this example (and very often) the data that we want is actually hosted on the [Sequence Read Archive (SRA)](https://www.ncbi.nlm.nih.gov/sra), so the sample `GSM3168965` gets another identifier associated to it. In the SRA it's known as `SRR7244429`. And on the sample's SRA page you can actually look at individual reads from the sequencing run (click on the `Reads` tab): https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR7244429


But we can't download it directly. We need to use the `NCBI SRA Toolkit`, available at: https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software. Development information is on their github repository: https://github.com/ncbi/sra-tools. After the toolkit is installed, we can download the files using the tool `fastq-dump`, documented at: https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software.


Specifically, for this sample we'd use the command: `fastq-dump -I --split-files SRR7244429`
Because it's a paired end read Illumina run it produces two `.fastq` files

This downloads two files of 3.7GB each, `SRR7244429\_1.fastq` and `SRR7244429\_2.fastq`. You have to hope your connection doesn't get interrupted.  If you are unhappy with the official documentation (as many are), here is an additional helpful resource: https://edwards.sdsu.edu/research/fastq-dump/

Thankfully, there is a (much much) faster option: `fasterq-dump` (but it's only available for Mac and Linux): https://github.com/ncbi/sra-tools/wiki/HowTo:-fasterq-dump

If you decide to use `fasterq-dump`, you can download the data with the command `fasterq-dump SRR7244429`

Finally, to help you navigate the confusing and teacherous world of getting other people's data in bioinformatics (welcome!) below is a helpful diagram of how to find the sample SRA identifier, which is what you need to run `fastq-dump` or `fasterq-dump`. Get used to this gymnastics, being able to do it is like having a super power.



![geo_to_sra](https://user-images.githubusercontent.com/12504176/52777648-270c7200-2ff9-11e9-9a1d-2b14b0a79300.png)

